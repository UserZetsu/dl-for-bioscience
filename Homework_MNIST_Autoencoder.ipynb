{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAWVbhB16p-U"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "# Homework: Autoencoding MNIST and Celebrity Faces\n",
        "\n",
        "\n",
        "> **Due Date: March 5th, 2025 @ 1:00pm**\n",
        ">\n",
        "> Please turn in this completed notebook via Google classroom. Email clay.smyth@ucsf.edu if you run into any issues.\n",
        "\n",
        "**Collaboration policy and more**\n",
        "\n",
        "You're welcome (and highly encouraged) to work with and discuss this homework assignment with others in the class, and feel free to use any resources (textbooks, online notebooks, etc). The only requirement is that the final notebook that you turn in must be your own written work (no copy and pasting, please).\n",
        "\n",
        "**Overview**\n",
        "\n",
        "In class, we cover how Hinton and Salakhutdinov's 2006 Science Paper, [\"Reducing the Dimensionality of Data with Neural Networks\"](https://www.science.org/doi/10.1126/science.1127647) was one of the first demonstrations of unsupervised pretraining for use in training deep neural networks. In this homework, we'll implement autoencoders in the context of MNIST. Additionally, as an optional assignment, a similar architecture can be used for a subset of CelebA dataset of celebrity faces.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "px8y6lmq6p-V"
      },
      "source": [
        "## Before you get started\n",
        "\n",
        "**1) Background reading**\n",
        "\n",
        "Please Read Hinton and Salakhutdinov's 2006 seminal work on deep autoencoders (https://www.science.org/doi/10.1126/science.1127647), as this notebook aims to recreate this important work. A few questions to think about as you read that will help you in this assignment:\n",
        "  - What architecture do they use for their deep autoencoders?\n",
        "  - Why were deep neural networks so much harder to train in 2006?\n",
        "\n",
        "**2) How to run this notebook**\n",
        "\n",
        "This Jupyter Notebook can be used in two ways:\n",
        "* *Option 1: Download the notebook*\n",
        "\n",
        "  We've included all the imports necessary for this homework. Please make sure you're running Python 3 with PyTorch (and Torchvision) installed and ready to go, along with NumPy and Matplotlib. Although you might find that these models train a bit faster on GPU, this homework assignment should be doable on most modern laptops. If you're having trouble please let us know ASAP.\n",
        "\n",
        "* *Option 2: Run it online on Google Colaboratory*\n",
        "\n",
        "  - Colab gives access to a GPU, so it could be useful in case you don't have CUDA installed on your computer (**Note: you can use this as an opportunity to get started on GPU training, but we recommend you develop your model and make sure everything works on CPU first**)\n",
        "  - Make a copy of this notebook in your Google Drive folder: \"File\" -> \"Save a copy in Drive...\"\n",
        "  - By default, Colab does not make GPUs available, but you can easily access them by selecting GPU in \"Runtime\" -> \"Change runtime type...\"\n",
        "  - Remember that Colab runs in a temporary virtual machine, so all the data created while running the notebook will be lost at the end of the session, or when the runtime disconnects due to inactivity. To preserve data between sessions, there are a couple of options:\n",
        "    * you can link Colab to your personal Google Drive by mounting it on your runtime, see first cell below.\n",
        "    * you can download/upload files from the Files tab on the right sidebar.\n",
        "\n",
        "**3) How to complete this assignment**\n",
        "\n",
        "  - Fill out the relevant code blocks as indicated\n",
        "  - Answer questions by writing them directly in the text block. Please keep your written answers concise, most are meant to be answered in a sentence or two.\n",
        "  - Make figures showing your results and add comments with your observations.\n",
        "\n",
        "**4) Optional exercise: CelebA Data**\n",
        "\n",
        "Whereas MNIST is a toy dataset built into PyTorch, we can also examine a more complex feature space using a subset of 90,000 celebrity portraits from CelebA (see [Liu et al. (2014), \"Deep Learning Face Attributes in the Wild\"](https://arxiv.org/abs/1411.7766)). This is an optional part of the homework, but is a nice way to see how autoencoders perform on other types of visual data. There will be a .zip file of the relevant celebrity faces dataset on the Google Classroom link.\n",
        "\n",
        "***Let's start!***\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykN_eZdJ6p-f"
      },
      "source": [
        "## Train an autoencoder on MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzyVPwhkMWk3"
      },
      "source": [
        "The following command can be used to mount your personal Google Drive folder on the temporary virtual machine, so you can recover data between sessions (follow the instructions, you'll need an authorization code). Additional info [here](https://colab.research.google.com/notebooks/io.ipynb#scrollTo=u22w3BFiOveA).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "STvHSt3zICjF"
      },
      "outputs": [],
      "source": [
        "# # Skip this cell if running locally\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgkNXdEr6p-X"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/Caskroom/miniforge/base/envs/dl-bioscience/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# Import all the necessary libraries\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from IPython.display import Image, display\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "from tqdm.autootebook import tqdm \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "es5SJPnnVISe"
      },
      "source": [
        "You shouldn't need CUDA for this assignment, but if you want a head start, or if you just want to see the difference between using a CPU versus a GPU, set `use_cuda = True` below.\n",
        "You can check if CUDA is available on your computer with: `torch.cuda.is_available()`\n",
        "\n",
        "If you are working on Colab, make sure to activate the GPU (\"Runtime\" -> \"Change runtime type...\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "EKT2zNJR6Rwj"
      },
      "outputs": [],
      "source": [
        "use_cuda = False\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "28wNsWmC6Q63"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(7);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBrzn_tnFKsM"
      },
      "source": [
        "> **Question 0.1) Why is it important to set the seed for the random number generator?**\n",
        "\n",
        "*Setting a seed ensures reproducibility in your code. If you do not set a seed, you will get different results everytime you run your model. Therefore, when you change hyperparameters or split your data, it will change your output everytime you run your model.*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUNoP7qY6p-g"
      },
      "source": [
        "### 1. MNIST Dataset\n",
        "\n",
        "As noted in class, MNIST has been widely used to benchmark new deep learning architectures and is already built into PyTorch. We provide this data as a starting point, again noting that the mean and std of the training set are calculated to be 0.1307 and 0.3081, respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8H20Wcmu6p-h",
        "outputId": "e88d9f2a-b0bc-43d8-9c8c-1a6af36aa1fc"
      },
      "outputs": [],
      "source": [
        "preprocessing = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(\n",
        "    './bmi219_downloads', train=True, download=True,\n",
        "    transform=preprocessing)\n",
        "\n",
        "test_dataset = datasets.MNIST(\n",
        "    './bmi219_downloads', train=False, download=True,\n",
        "    transform=preprocessing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oay1ii680sfO",
        "outputId": "3202b732-8239-4afe-91cc-bc3e5c5217f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: ./bmi219_downloads\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
            "           )\n",
            "Dataset MNIST\n",
            "    Number of datapoints: 10000\n",
            "    Root location: ./bmi219_downloads\n",
            "    Split: Test\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
            "           )\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# assignment code \n",
        "print(train_dataset[123][0].size())\n",
        "\n",
        "# my code\n",
        "print(train_dataset)\n",
        "print(test_dataset)\n",
        "\n",
        "type(train_dataset[0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnPPEsT96p-l"
      },
      "source": [
        "> **Q1.1) How many examples do the training set and test set have?**\n",
        "\n",
        "Train and test set has 60000 and 10000 samples respectively \n",
        "\n",
        "> **Q1.2) What's the format of each input example? Can we directly put these into a fully-connected layer?**\n",
        "\n",
        "Each input example is a tensor object which can be an input example into a fully-connected layer, but you can also choose to batch them as an input.\n",
        "\n",
        "> **Q1.3) Why do we normalize the input data for neural networks?**\n",
        "\n",
        "Data should be normalized so that large or small values do not skew the neural network's weights, making the model harder to optimize.\n",
        "\n",
        "> **Q1.4) In this scenario, MNIST is already split into a training set and a test set. What is the purpose of dataset splitting (and specifically, the purpose of a test set)? For modern deep learning, a three-way split into training, validation, and test sets is usually preferred, why?**\n",
        "\n",
        "A common problem with deep learning models is that it can easily overfit. A test set would be an untouched dataset used to test the generalizability of the model. In modern deep learning, a validation set is added to evaluate the model every epoch, allowing for hyperparameter tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vr83wABJ6p-m"
      },
      "source": [
        "### 2. Using DataLoaders for MNIST\n",
        "\n",
        "Set up the DataLoader objects below. Although the arguments are prepopulated, you may need to change the batch sizes or other arguments during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Df46Ok2t6p-n"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32  # <-- Please change this as necessary\n",
        "NUM_WORKERS = 1  # <-- Use more workers for more CPU threads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Tx21NwCGqwE-"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=NUM_WORKERS)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvgrdGuhdwKt",
        "outputId": "d2387174-b4c0-430f-f2ba-efacc51e7e7d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 1, 28, 28])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "one_batch=next(iter(train_loader))\n",
        "one_batch[0].size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jL6Zs5z6p-r"
      },
      "source": [
        "> **Q2.1) It's recommended to shuffle the training data over each epoch, but this isn't typically the case for the test set, why?**\n",
        "\n",
        "The test set is the final dataset you test your model on and in order for consistent comparison, you want to keep the test set unshuffled. \n",
        "\n",
        "> **Q2.2) What seems to be a good batch size for training? What happens if you train with a batch size of 1? What about a batch size equal to the total training set?**\n",
        "\n",
        "Good batch sizes are often in powers of two because physical processors of GPU or CPU are also in powers of two. If I train a model with a batch size of one, my gradients will update with every example, making my model run slow and inefficient. If I train a model with a batch size equal to my total training set, my gradient will update once, making my model run slow and poorly generalize. \n",
        "\n",
        "> **Q2.3) The PyTorch DataLoader object is an iterator that generates batches as it's called. Try to pull a few images from the training set to see what these images look like. Does the DataLoader return only the images? What about the labels?**\n",
        "\n",
        "The dataloader returns a tuple containing the image and the label."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMlogSbL6p-s"
      },
      "source": [
        "### 3. Define your neural network architecture\n",
        "\n",
        "With your data and dataloaders appropriately set, you're ready to define a network architecture. In this homework, we'll ask you to evaluate two different architectures.\n",
        "\n",
        "For the first (we'll call it `HNet` in this homework), please implement Hinton's 2006 architecture of 7-hidden layers:\n",
        "\n",
        "```[784 x 1000 x 500 x 250 x 2 x 250 x 500 x 1000 x 784]. ```\n",
        "\n",
        "For the second, implement your own autoencoder architecture, `MyNet`, again using a bottleneck dimension of 2. As a note, the larger your model, the longer it will take to train. Can you achieve similar performance to the model above using a more condensed model?\n",
        "\n",
        "**Tips:**\n",
        "* Try different activation functions (Tanh, Sigmoid, ReLU, etc)\n",
        "* A sequence of layers can be defined more easily using `nn.Sequential`, see [docs](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential)\n",
        "* Split your network into an `.encoder()` and a `.decoder()`, that will be called sequentially in `.forward()`. This will be useful later on when we'll ask to visualize the low-dimensional embeddings (\"latent space\") produced by the encoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gGK2j8UM6p-t"
      },
      "outputs": [],
      "source": [
        "class HNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        ### Implement a version of Hinton's 2006 Autoencoder,\n",
        "        ### using a bottleneck latent dimension of 2\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(784, 1000),\n",
        "            nn.Linear(1000, 500),\n",
        "            nn.Linear(500, 250),\n",
        "            nn.Linear(250, 2)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(2, 250),\n",
        "            nn.Linear(250, 500),\n",
        "            nn.Linear(500, 1000),\n",
        "            nn.Linear(1000, 784),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        ### Implement the forward pass\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_Grvigg6p-x"
      },
      "outputs": [],
      "source": [
        "class MyNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        ### Fill in your network architecture here\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(784, 1000),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1000, 500),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(500, 250),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(250, 2)\n",
        "            \n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(2, 250),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(250, 500),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(500, 1000),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1000, 784)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        ### Implement the forward pass\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqQ-CAnlYad2"
      },
      "source": [
        "> **Q3.1) What activation functions did you use, and why?**\n",
        "\n",
        "I used ReLU because it is simple and is standard. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2rGw2FD6p-2"
      },
      "source": [
        "### 4. Write your own training function\n",
        "\n",
        "Write your own training function that takes your **model**, an **optimizer**, and a **training criterion**, and iterates over the **training set**.\n",
        "* *Hint*: Because an autoencoder is a form of unsupervised learning, we won't need to use the labels like in the MNIST classification example. Keep in mind the format of the images and whether they're compatible with feed-forward networks.\n",
        "* For each epoch, print and record (in an array or list) the training loss.\n",
        "* You may want to save the model and its weights on file at regular intervals ([checkpointing](https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-model-for-inference)). In order to visualize the autoencoder's learning process, we suggest to save at least three timepoints: early, intermediate, and final (for instance, if your model converges after 60 epochs, save your model at 5 epochs, 30 epochs, and 60 epochs).\n",
        "\n",
        "A few useful tips:\n",
        "- Feel free to look at the MNIST classification notebook from previous recitations and use it as a template.\n",
        "- Printing out the intermediate variables and their shape at each step can be helpful for debugging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2vn3O8L6p-2"
      },
      "outputs": [],
      "source": [
        "def checkpoint(model, filename):\n",
        "      torch.save(model.state_dict(), filename)\n",
        "\n",
        "def train(train_loader, model, optimizer, criterion,\n",
        "          n_epochs=10, **kwargs):\n",
        "    losses = []   \n",
        "    ### Define your training loop here\n",
        "    for epoch in tqdm(range(n_epochs)):\n",
        "      for batch_X, _ in tqdm(train_loader):\n",
        "            batch_X = batch_X.view(batch_X.size(0), -1)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            outputs = model(batch_X)\n",
        "            \n",
        "            loss = criterion(outputs, batch_X)\n",
        "            \n",
        "            loss.backward()\n",
        "            \n",
        "            optimizer.step()\n",
        "      \n",
        "      # Stopping\n",
        "      counter = 0\n",
        "      try: \n",
        "            if epoch in kwargs['stopping']:\n",
        "                  if counter == 0: \n",
        "                        checkpoint(model, \"autoencoder_checkpoints/early.pt\")\n",
        "                        counter += 1\n",
        "                  elif counter == 1: \n",
        "                        checkpoint(model, \"autoencoder_checkpoints/mid.pt\")\n",
        "                        counter += 1\n",
        "                  else: \n",
        "                        checkpoint(model, \"autoencoder_checkpoints/late.pt\")\n",
        "      except:\n",
        "            continue\n",
        "      \n",
        "      print(f'Epoch: {epoch}. Loss: {loss.item()}')\n",
        "      losses.append(loss.item())\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsMeeItp6p-6"
      },
      "source": [
        "### 5. Define your optimization and evaluation criterion\n",
        "\n",
        "Define an optimizer and criterion (loss function) for your neural network training. To setup your optimizer, you'll have to instantiate your models above, and choose a learning rate. Try a few different optimizers and learning rates to get a sense of what will train within a reasonable timeframe (if your deep network isn't too deep, reaching convergence shouldn't take more than 5-10 minutes with the right choice of learning rate and optimizer)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WQBWlyJcj7w"
      },
      "source": [
        "> **Q5.1) What loss function is suited to this problem?**\n",
        "\n",
        "Mean squared error.\n",
        "\n",
        "> **Q5.2) Try a few optimizers, what seemed to work best?**\n",
        "\n",
        "ReLU\n",
        "\n",
        "> **Q5.3) What's the effect of choosing different batch sizes?**\n",
        "\n",
        "A difference in training times, generalizabiity, and gradient updates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ftxeVJJP6p-7"
      },
      "outputs": [],
      "source": [
        "### Instantiate your model\n",
        "model = HNet()\n",
        "### Define your loss function (training criterion)\n",
        "criterion = nn.MSELoss()\n",
        "### Choose your optimizer\n",
        "optimizer = optim.Adam(params=model.parameters(), lr = 1e-6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zudx4FKI6p_C"
      },
      "source": [
        "### 6. Run your training loop\n",
        "\n",
        "It's a great idea to monitor the early epochs of your training (\"babysit your training\") to keep an eye on learning. Does the learning rate seem too high? too low?\n",
        "\n",
        "(**Hint: it's recommended that you just test a single epoch at a time while you write your training function, to debug and make sure everything is working appropriately.**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "J87zUaXX6p_D"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:29<00:00, 64.41it/s]\n",
            "100%|██████████| 1875/1875 [00:31<00:00, 60.23it/s]\n",
            "100%|██████████| 1875/1875 [00:35<00:00, 52.48it/s]\n",
            "100%|██████████| 1875/1875 [00:34<00:00, 54.14it/s]\n",
            "100%|██████████| 1875/1875 [00:36<00:00, 51.57it/s]\n",
            "100%|██████████| 1875/1875 [00:34<00:00, 54.09it/s]\n",
            "100%|██████████| 1875/1875 [00:35<00:00, 52.44it/s]\n",
            "100%|██████████| 1875/1875 [00:35<00:00, 52.55it/s]\n",
            "100%|██████████| 1875/1875 [00:40<00:00, 46.63it/s]\n",
            "100%|██████████| 1875/1875 [00:36<00:00, 51.19it/s]\n",
            "100%|██████████| 10/10 [05:53<00:00, 35.33s/it]\n"
          ]
        }
      ],
      "source": [
        "### Set a number of training epochs and train your model.\n",
        "losses = train(train_loader, model, optimizer, criterion, n_epochs=10, stopping = [5, 10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoOJQt6vFADr"
      },
      "source": [
        "In your training loop, we requested that you store your training loss for each epoch. Using Matplotlib, please plot your training loss as a function of epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "xycLVQK-jwiB"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "### Plot loss curve using Matplotlib\n",
        "x = np.arange(0, len(losses), 1)\n",
        "y = losses\n",
        "\n",
        "plt.plot(x, y)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Losses\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XitAd61L6p_M"
      },
      "source": [
        "> **Q6.1)  How do you know when your network is done training?**\n",
        "\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxomi9w5kxIx"
      },
      "source": [
        "Another way to check if your models (`HNet` and `MyNet`) are well trained is to plot a few image reconstructions to see how well your models do."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pjS79M0oDj_"
      },
      "outputs": [],
      "source": [
        "# extract 6 figures from training DataLoader\n",
        "mini_batch, _ = next(iter(train_loader))\n",
        "n_examples = min(6, mini_batch.shape[0])\n",
        "examples = mini_batch[:n_examples]\n",
        "\n",
        "# compute reconstructions\n",
        "with torch.no_grad():\n",
        "    reconstr_examples = model.forward(\n",
        "        examples.view(n_examples, -1).to(device))\n",
        "\n",
        "# save image with original v. reconstructed images\n",
        "comparison = torch.cat([\n",
        "    examples,\n",
        "    reconstr_examples.view(-1, 1, 28, 28).cpu()])\n",
        "save_image(comparison.cpu(), 'training_reconstruction.png', nrow=n_examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XG_F4XTqwk9"
      },
      "outputs": [],
      "source": [
        "Image('training_reconstruction.png', width=300)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxNZwHPUGxKu"
      },
      "source": [
        "> **Q6.2) What does `torch.no_grad()` do?**\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FC8PXHyR6p_Q"
      },
      "source": [
        "### 7. Visualize the learning process\n",
        "\n",
        "We'll next try to visualize how well the model is learning on the **test set**. To do this, we'll first visualize the \"learning process\" by viewing reconstruction at various stages.\n",
        "\n",
        "* Using your checkpoints saved during training, plot a batch of images from the test set and their corresponding reconstructions based on each of your saved models over time. You should see the quality of the reconstructions improving over time.\n",
        "* To visualize images, you can use the helper functions provided below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDO9E6Vl6p_N"
      },
      "outputs": [],
      "source": [
        "### Helper Functions for Plotting Multiple Images\n",
        "\n",
        "def imshow(inp,\n",
        "           figsize=(10,10),\n",
        "           mean=0.1307, # for MNIST train\n",
        "           std=0.3081, # for MNIST train\n",
        "           title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.cpu().detach()\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array(mean)\n",
        "    std = np.array(std)\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "def reconstructions_from_batch(model, batch):\n",
        "    batch = batch.view(-1, 28 * 28).to(device)\n",
        "    reconstruction = model(batch)\n",
        "    return reconstruction.reshape(batch.shape[0],1,28,28)\n",
        "\n",
        "# Get a batch of training data\n",
        "batch, classes = next(iter(test_loader))\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(batch)\n",
        "imshow(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2edUEVG3Rev"
      },
      "outputs": [],
      "source": [
        "### Iterate over checkpoints and plot reconstruction\n",
        "### figures from the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfhuSg4D6p_R"
      },
      "source": [
        "### 8. Visualize the latent space\n",
        "\n",
        "As discussed in class, the first half of an autoencoder (the *encoder*) maps the original input into a lower-dimensional latent space.\n",
        "* Just as shown in Hinton and Salakhutdinov, run your test set of 10,000 MNIST digits through the **encoding layer** of one of the trained networks above. Each sample should readily map to a 2-dimension point. To do this, it will be helpful to fill out a new function, **encode** below, that takes in your trained model and the `test_dataloader` to produce 2d latent embeddings and their corresponding labels.\n",
        "* Plot each point in these two dimensions, and color each point in this **latent space** by their known **labels**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNg0PfrK4gzn"
      },
      "outputs": [],
      "source": [
        "### Write a helper function to grab examples from the test_loader to generate\n",
        "### pairs of embeddings and their associated labels\n",
        "\n",
        "def encode(model, device, test_loader):\n",
        "  #### Fill this in! ####\n",
        "  latent_embeddings # get the latent embeddings, which will ultimately be a vector of x, y coordinates\n",
        "  labels # this should match the dim of latent_embeddings, so each pair of coordinates has an associated label\n",
        "  return latent_embeddings, labels\n",
        "\n",
        "### Plot latent space representation color-coded\n",
        "### according to their \"true\" labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuGkujKgGPEi"
      },
      "source": [
        "> **Q8.1) Does your autoencoder separate out different classes effectively? What classes seem to be closer and what classes are farther apart in this latent space?**\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78___-BU6p_S"
      },
      "source": [
        "## Optional (advanced): Train an autoencoder on CelebA Faces\n",
        "\n",
        "Real-world images tend to be far more complex than digits from MNIST. As an optional exercise for your own interest, or for students looking for more experience, we'll investigate a subset of CelebA below.\n",
        "\n",
        "We provide the images in a .zip file (`faces.zip`) in the class's Google Drive folder, which contains a \"train\" and \"test\" set of 80k and 10k images, respectively. Although these are color, RGB images, below we've set up the datasets to convert these to grayscale with precomputed means (0.4401) and stds (0.2407), for convenience and easier compute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1K6o1Wr88EXj"
      },
      "outputs": [],
      "source": [
        "### Download faces.zip and unzip it into bmi219_downloads/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nM7WXmAu6p_T"
      },
      "outputs": [],
      "source": [
        "preprocessing = transforms.Compose([\n",
        "    transforms.Grayscale(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4401,), (0.2407,)),\n",
        "])\n",
        "\n",
        "train_dataset = datasets.ImageFolder(\n",
        "    'bmi219_downloads/Faces/train',\n",
        "    transform=preprocessing)\n",
        "\n",
        "test_dataset = datasets.ImageFolder(\n",
        "    'bmi219_downloads/Faces/test',\n",
        "    transform=preprocessing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQn4cgBW6p_X"
      },
      "source": [
        "As above, you'll want to:\n",
        "\n",
        "1. set up your dataloaders and visualize some of the images\n",
        "2. set up your autoencoder network architecture\n",
        "3. define your training criterion and optimizer\n",
        "4. train your network\n",
        "    \n",
        "In this case, you should be able to reuse much of your code from above. Consider a few questions:\n",
        "\n",
        "1. How well do complex images like faces work with a latent dimension of 2?\n",
        "2. Do reconstructions look better with a larger bottleneck?\n",
        "3. What kind of features are poorly reconstructed? What happens to sunglasses, hats, and hands?\n",
        "4. Try sampling the 2-d latent space close to existing examples (by adding some noise...) or randomly. What do the generated images look like?"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dl-bioscience",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
